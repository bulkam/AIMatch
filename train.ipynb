{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_preprocessing' from 'c:\\\\Users\\\\bmk1bj\\\\Documents\\\\GIT_repositories\\\\AIMatch\\\\data_preprocessing.py'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_preprocessing as prep\n",
    "import importlib\n",
    "\n",
    "import train_b\n",
    "importlib.reload(train_b)\n",
    "from train_b import score, score_sample, predictions_to_goals, prediction_to_goals, show_predictions\n",
    "\n",
    "importlib.reload(prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "\n",
    "- [x] Split train and val randomly\n",
    "- [] Drop early matches on dataframe level\n",
    "- [] y = [home_goals - away_goals, total goals]\n",
    "- [x] model with two unrelated outputs   - OK\n",
    "- [] sample_weight extended by tournament_group\n",
    "- [] consider team strength trend this year (or this cup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relevant labeled matches: 5167/14644\n",
      "X shape =  (5167, 405)\n",
      "Y shape =  (5167, 2)\n",
      "sample weights shape =  (5167,)\n",
      "X shape =  (48, 405)\n",
      "Y shape =  (48, 2)\n",
      "sample weights shape =  (48,)\n",
      "    Reference values:\n",
      "0:0 846 / 2068  - 1.64 points per match\n",
      "1:0 943 / 2068  - 1.82 points per match\n",
      "1:1 864 / 2068  - 1.67 points per match\n",
      "0:1 394 / 2068  - 0.76 points per match\n",
      "2:1 914 / 2068  - 1.77 points per match\n",
      "2:0 853 / 2068  - 1.65 points per match\n"
     ]
    }
   ],
   "source": [
    "dataset = prep.Dataset()\n",
    "X_train, Y_train, X_val, Y_val, X_test, sample_weights_train, sample_weights_val = dataset.get_input_data(label_weights=[1, 1], sample_weights_degree=2, random_split=False, keep_tail=3)\n",
    "results_df = pd.read_csv(\"Data/results.txt\")\n",
    "\n",
    "# Reference values\n",
    "# = total score for validation data if results are hard-coded and all same without any prediction\n",
    "# all models should overcome those values\n",
    "print(\"    Reference values:\")\n",
    "max_score = 4 * len(Y_val)\n",
    "ref_score_1 = score(np.zeros(Y_val.shape) * dataset.label_weights, Y_val, label_weights=dataset.label_weights) # 0:0\n",
    "print(\"0:0\", ref_score_1, \"/\", max_score, \" - %s points per match\" % (np.round(ref_score_1/len(Y_val), 2)))\n",
    "ref_score_2 = score(np.ones(Y_val.shape) * dataset.label_weights, Y_val, label_weights=dataset.label_weights) # 1:0\n",
    "print(\"1:0\", ref_score_2, \"/\", max_score, \" - %s points per match\" % (np.round(ref_score_2/len(Y_val), 2)))\n",
    "Y_pred = np.ones(Y_val.shape) * dataset.label_weights # 1:1\n",
    "Y_pred[:, 0] = 0\n",
    "ref_score_3 = score(Y_pred, Y_val, label_weights=dataset.label_weights) \n",
    "print(\"1:1\", ref_score_3, \"/\", max_score, \" - %s points per match\" % (np.round(ref_score_3/len(Y_val), 2)))\n",
    "Y_pred = np.ones(Y_val.shape) * dataset.label_weights # 0:1\n",
    "Y_pred[:, 0] = -1\n",
    "ref_score_3 = score(Y_pred, Y_val, label_weights=dataset.label_weights) \n",
    "print(\"0:1\", ref_score_3, \"/\", max_score, \" - %s points per match\" % (np.round(ref_score_3/len(Y_val), 2)))\n",
    "Y_pred = np.ones(Y_val.shape) # 2:1\n",
    "Y_pred[:, 1] = 2\n",
    "ref_score_3 = score(Y_pred * dataset.label_weights, Y_val, label_weights=dataset.label_weights) \n",
    "print(\"2:1\", ref_score_3, \"/\", max_score, \" - %s points per match\" % (np.round(ref_score_3/len(Y_val), 2)))\n",
    "Y_pred = 2 * np.ones(Y_val.shape) # 2:0\n",
    "ref_score_3 = score(Y_pred * dataset.label_weights, Y_val, label_weights=dataset.label_weights) \n",
    "print(\"2:0\", ref_score_3, \"/\", max_score, \" - %s points per match\" % (np.round(ref_score_3/len(Y_val), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear\n",
      "Linear\n",
      "740 / 2068  - 1.43 points per match\n",
      "Val:\n",
      "Uruguay  x  Chile :  [0.57666016 1.15576172] - [0. 1.]  ...................  output (weighted):  [-0.57910156  0.57666016] [0. 1.]    original:  [-0.57910156  0.57666016] [0. 1.]\n",
      "Argentina  x  Paraguay :  [ 0.89697266 -0.32373047] - [1. 1.]  ...................  output (weighted):  [1.22070312 0.89697266] [1. 1.]    original:  [1.22070312 0.89697266] [1. 1.]\n",
      "Scotland  x  Croatia :  [3.81201172 6.23388672] - [-2.  3.]  ...................  output (weighted):  [-2.421875    3.81201172] [-2.  3.]    original:  [-2.421875    3.81201172] [-2.  3.]\n",
      "England  x  Czech Republic :  [ 1.38916016 -0.44970703] - [1. 1.]  ...................  output (weighted):  [1.83886719 1.38916016] [1. 1.]    original:  [1.83886719 1.38916016] [1. 1.]\n",
      "Spain  x  Slovakia :  [2.90039062 0.44140625] - [5. 5.]  ...................  output (weighted):  [2.45898438 2.90039062] [5. 5.]    original:  [2.45898438 2.90039062] [5. 5.]\n",
      "Sweden  x  Poland :  [1.50878906 2.3125    ] - [1. 3.]  ...................  output (weighted):  [-0.80371094  1.50878906] [1. 3.]    original:  [-0.80371094  1.50878906] [1. 3.]\n",
      "Germany  x  Hungary :  [2.89453125 0.9375    ] - [0. 2.]  ...................  output (weighted):  [1.95703125 2.89453125] [0. 2.]    original:  [1.95703125 2.89453125] [0. 2.]\n",
      "Portugal  x  France :  [1.69580078 1.63623047] - [0. 2.]  ...................  output (weighted):  [0.05957031 1.69580078] [0. 2.]    original:  [0.05957031 1.69580078] [0. 2.]\n",
      "Ecuador  x  Peru :  [2.98095703 3.69677734] - [0. 2.]  ...................  output (weighted):  [-0.71582031  2.98095703] [0. 2.]    original:  [-0.71582031  2.98095703] [0. 2.]\n",
      "Brazil  x  Colombia :  [ 2.34619141 -0.60302734] - [1. 2.]  ...................  output (weighted):  [2.94921875 2.34619141] [1. 2.]    original:  [2.94921875 2.34619141] [1. 2.]\n",
      "Bolivia  x  Uruguay :  [2.234375   3.24511719] - [-2.  2.]  ...................  output (weighted):  [-1.01074219  2.234375  ] [-2.  2.]    original:  [-1.01074219  2.234375  ] [-2.  2.]\n",
      "Wales  x  Denmark :  [-0.01171875  1.60253906] - [-4.  4.]  ...................  output (weighted):  [-1.61425781 -0.01171875] [-4.  4.]    original:  [-1.61425781 -0.01171875] [-4.  4.]\n",
      "Netherlands  x  Czech Republic :  [1.22460938 0.75976562] - [-2.  2.]  ...................  output (weighted):  [0.46484375 1.22460938] [-2.  2.]    original:  [0.46484375 1.22460938] [-2.  2.]\n",
      "Belgium  x  Portugal :  [3.94238281 2.90039062] - [1. 1.]  ...................  output (weighted):  [1.04199219 3.94238281] [1. 1.]    original:  [1.04199219 3.94238281] [1. 1.]\n",
      "Brazil  x  Ecuador :  [1.70507812 0.02539062] - [0. 1.]  ...................  output (weighted):  [1.6796875  1.70507812] [0. 1.]    original:  [1.6796875  1.70507812] [0. 1.]\n",
      "Croatia  x  Spain :  [0.86181641 1.74560547] - [-2.  5.]  ...................  output (weighted):  [-0.88378906  0.86181641] [-2.  5.]    original:  [-0.88378906  0.86181641] [-2.  5.]\n",
      "France  x  Switzerland :  [1.47509766 1.59033203] - [0. 3.]  ...................  output (weighted):  [-0.11523438  1.47509766] [0. 3.]    original:  [-0.11523438  1.47509766] [0. 3.]\n",
      "Argentina  x  Bolivia :  [ 2.63574219 -0.95507812] - [3. 4.]  ...................  output (weighted):  [3.59082031 2.63574219] [3. 4.]    original:  [3.59082031 2.63574219] [3. 4.]\n",
      "Uruguay  x  Paraguay :  [ 0.35205078 -0.11572266] - [1. 1.]  ...................  output (weighted):  [0.46777344 0.35205078] [1. 1.]    original:  [0.46777344 0.35205078] [1. 1.]\n",
      "England  x  Germany :  [2.67822266 1.34619141] - [2. 2.]  ...................  output (weighted):  [1.33203125 2.67822266] [2. 2.]    original:  [1.33203125 2.67822266] [2. 2.]\n",
      "Mexico  x  Panama :  [2.06298828 1.40576172] - [3. 3.]  ...................  output (weighted):  [0.65722656 2.06298828] [3. 3.]    original:  [0.65722656 2.06298828] [3. 3.]\n",
      "Switzerland  x  Spain :  [0.32177734 1.16064453] - [0. 1.]  ...................  output (weighted):  [-0.83886719  0.32177734] [0. 1.]    original:  [-0.83886719  0.32177734] [0. 1.]\n",
      "Belgium  x  Italy :  [2.67578125 1.58984375] - [-1.  2.]  ...................  output (weighted):  [1.0859375  2.67578125] [-1.  2.]    original:  [1.0859375  2.67578125] [-1.  2.]\n",
      "Brazil  x  Chile :  [1.23535156 0.37890625] - [1. 1.]  ...................  output (weighted):  [0.85644531 1.23535156] [1. 1.]    original:  [0.85644531 1.23535156] [1. 1.]\n",
      "Czech Republic  x  Denmark :  [1.13671875 0.60058594] - [-1.  2.]  ...................  output (weighted):  [0.53613281 1.13671875] [-1.  2.]    original:  [0.53613281 1.13671875] [-1.  2.]\n",
      "Ukraine  x  England :  [0.92382812 2.296875  ] - [-4.  4.]  ...................  output (weighted):  [-1.37304688  0.92382812] [-4.  4.]    original:  [-1.37304688  0.92382812] [-4.  4.]\n",
      "Mexico  x  Nigeria :  [0.47216797 2.08837891] - [4. 4.]  ...................  output (weighted):  [-1.61621094  0.47216797] [4. 4.]    original:  [-1.61621094  0.47216797] [4. 4.]\n",
      "Uruguay  x  Colombia :  [1.6875     0.17285156] - [0. 0.]  ...................  output (weighted):  [1.51464844 1.6875    ] [0. 0.]    original:  [1.51464844 1.6875    ] [0. 0.]\n",
      "Argentina  x  Ecuador :  [1.59179688 0.59375   ] - [3. 3.]  ...................  output (weighted):  [0.99804688 1.59179688] [3. 3.]    original:  [0.99804688 1.59179688] [3. 3.]\n",
      "Qatar  x  El Salvador :  [4.15917969 0.0625    ] - [1. 1.]  ...................  output (weighted):  [4.09667969 4.15917969] [1. 1.]    original:  [4.09667969 4.15917969] [1. 1.]\n",
      "Brazil  x  Peru :  [1.94287109 0.35205078] - [1. 1.]  ...................  output (weighted):  [1.59082031 1.94287109] [1. 1.]    original:  [1.59082031 1.94287109] [1. 1.]\n",
      "Argentina  x  Colombia :  [ 2.23291016 -0.03466797] - [0. 1.]  ...................  output (weighted):  [2.26757812 2.23291016] [0. 1.]    original:  [2.26757812 2.23291016] [0. 1.]\n",
      "Italy  x  Spain :  [1.296875   0.72949219] - [0. 1.]  ...................  output (weighted):  [0.56738281 1.296875  ] [0. 1.]    original:  [0.56738281 1.296875  ] [0. 1.]\n",
      "England  x  Denmark :  [1.36914062 1.14160156] - [1. 2.]  ...................  output (weighted):  [0.22753906 1.36914062] [1. 2.]    original:  [0.22753906 1.36914062] [1. 2.]\n",
      "Senegal  x  Namibia :  [-3.12735958e+11  2.82325343e+11] - [-1.  2.]  ...................  output (weighted):  [-5.95061301e+11 -3.12735958e+11] [-1.  2.]    original:  [-5.95061301e+11 -3.12735958e+11] [-1.  2.]\n",
      "Senegal  x  Mozambique :  [-3.12735958e+11  2.82325343e+11] - [1. 1.]  ...................  output (weighted):  [-5.95061301e+11 -3.12735958e+11] [1. 1.]    original:  [-5.95061301e+11 -3.12735958e+11] [1. 1.]\n",
      "Brazil  x  Argentina :  [2.08398438 2.11523438] - [-1.  1.]  ...................  output (weighted):  [-0.03125     2.08398438] [-1.  1.]    original:  [-0.03125     2.08398438] [-1.  1.]\n",
      "Mexico  x  Trinidad and Tobago :  [3.1953125  0.00585938] - [0. 0.]  ...................  output (weighted):  [3.18945312 3.1953125 ] [0. 0.]    original:  [3.18945312 3.1953125 ] [0. 0.]\n",
      "England  x  Italy :  [0.88330078 0.58447266] - [0. 1.]  ...................  output (weighted):  [0.29882812 0.88330078] [0. 1.]    original:  [0.29882812 0.88330078] [0. 1.]\n",
      "Canada  x  Martinique :  [-3.12735958e+11  2.82325343e+11] - [3. 4.]  ...................  output (weighted):  [-5.95061301e+11 -3.12735958e+11] [3. 4.]    original:  [-5.95061301e+11 -3.12735958e+11] [3. 4.]\n",
      "United States  x  Haiti :  [4.26416016 0.78271484] - [1. 1.]  ...................  output (weighted):  [3.48144531 4.26416016] [1. 1.]    original:  [3.48144531 4.26416016] [1. 1.]\n",
      "Costa Rica  x  Guadeloupe :  [-3.12735958e+11  2.82325343e+11] - [2. 3.]  ...................  output (weighted):  [-5.95061301e+11 -3.12735958e+11] [2. 3.]    original:  [-5.95061301e+11 -3.12735958e+11] [2. 3.]\n",
      "Senegal  x  Zimbabwe :  [-3.12735958e+11  2.82325343e+11] - [1. 2.]  ...................  output (weighted):  [-5.95061301e+11 -3.12735958e+11] [1. 2.]    original:  [-5.95061301e+11 -3.12735958e+11] [1. 2.]\n",
      "Qatar  x  Panama :  [2.62695312 1.51953125] - [0. 3.]  ...................  output (weighted):  [1.10742188 2.62695312] [0. 3.]    original:  [1.10742188 2.62695312] [0. 3.]\n",
      "Senegal  x  Malawi :  [-3.12735958e+11  2.82325343e+11] - [1. 2.]  ...................  output (weighted):  [-5.95061301e+11 -3.12735958e+11] [1. 2.]    original:  [-5.95061301e+11 -3.12735958e+11] [1. 2.]\n",
      "Guatemala  x  Mexico :  [-1.91753911e+13  1.73107656e+13] - [-3.  3.]  ...................  output (weighted):  [-3.64861568e+13 -1.91753911e+13] [-3.  3.]    original:  [-3.64861568e+13 -1.91753911e+13] [-3.  3.]\n",
      "Haiti  x  Canada :  [1.24365234 1.93408203] - [-3.  4.]  ...................  output (weighted):  [-0.69042969  1.24365234] [-3.  4.]    original:  [-0.69042969  1.24365234] [-3.  4.]\n",
      "United States  x  Martinique :  [-3.12735958e+11  2.82325343e+11] - [5. 6.]  ...................  output (weighted):  [-5.95061301e+11 -3.12735958e+11] [5. 6.]    original:  [-5.95061301e+11 -3.12735958e+11] [5. 6.]\n",
      "Test:\n",
      "Qatar  x  Ecuador :  [-3.60282176e+12  3.25248140e+12] - [0. 2.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [0. 2.]    original:  [-6.85530316e+12 -3.60282176e+12] [0. 2.]\n",
      "England  x  Iran :  [-3.60282176e+12  3.25248140e+12] - [6. 2.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [6. 2.]    original:  [-6.85530316e+12 -3.60282176e+12] [6. 2.]\n",
      "Senegal  x  Netherlands :  [-3.60282176e+12  3.25248140e+12] - [0. 2.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [0. 2.]    original:  [-6.85530316e+12 -3.60282176e+12] [0. 2.]\n",
      "United States  x  Wales :  [-3.60282176e+12  3.25248140e+12] - [1. 1.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [1. 1.]    original:  [-6.85530316e+12 -3.60282176e+12] [1. 1.]\n",
      "Argentina  x  Saudi Arabia :  [-3.60282176e+12  3.25248140e+12] - [1. 2.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [1. 2.]    original:  [-6.85530316e+12 -3.60282176e+12] [1. 2.]\n",
      "Denmark  x  Tunisia :  [-3.60282176e+12  3.25248140e+12] - [0. 0.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [0. 0.]    original:  [-6.85530316e+12 -3.60282176e+12] [0. 0.]\n",
      "Mexico  x  Poland :  [-3.60282176e+12  3.25248140e+12] - [0. 0.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [0. 0.]    original:  [-6.85530316e+12 -3.60282176e+12] [0. 0.]\n",
      "France  x  Australia :  [-4.27232771e+12  3.85688423e+12] - [4. 1.]  ...................  output (weighted):  [-8.12921194e+12 -4.27232771e+12] [4. 1.]    original:  [-8.12921194e+12 -4.27232771e+12] [4. 1.]\n",
      "Morocco  x  Croatia :  [-3.60282176e+12  3.25248140e+12] - [0. 0.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [0. 0.]    original:  [-6.85530316e+12 -3.60282176e+12] [0. 0.]\n",
      "Germany  x  Japan :  [-3.60282176e+12  3.25248140e+12] - [1. 2.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [1. 2.]    original:  [-6.85530316e+12 -3.60282176e+12] [1. 2.]\n",
      "Spain  x  Costa Rica :  [-3.60282176e+12  3.25248140e+12] - [7. 0.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [7. 0.]    original:  [-6.85530316e+12 -3.60282176e+12] [7. 0.]\n",
      "Belgium  x  Canada :  [-3.60282176e+12  3.25248140e+12] - [1. 0.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [1. 0.]    original:  [-6.85530316e+12 -3.60282176e+12] [1. 0.]\n",
      "Switzerland  x  Cameroon :  [-3.60282176e+12  3.25248140e+12] - [1. 0.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [1. 0.]    original:  [-6.85530316e+12 -3.60282176e+12] [1. 0.]\n",
      "Uruguay  x  South Korea :  [-3.60282176e+12  3.25248140e+12] - [0. 0.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [0. 0.]    original:  [-6.85530316e+12 -3.60282176e+12] [0. 0.]\n",
      "Portugal  x  Ghana :  [-3.60282176e+12  3.25248140e+12] - [3. 2.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [3. 2.]    original:  [-6.85530316e+12 -3.60282176e+12] [3. 2.]\n",
      "Brazil  x  Serbia :  [-3.60282176e+12  3.25248140e+12] - [3. 2.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [3. 2.]    original:  [-6.85530316e+12 -3.60282176e+12] [3. 2.]\n",
      "Wales  x  Iran :  [-3.60282176e+12  3.25248140e+12] - [0. 2.]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [0. 2.]    original:  [-6.85530316e+12 -3.60282176e+12] [0. 2.]\n",
      "Qatar  x  Senegal :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Netherlands  x  Ecuador :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "England  x  United States :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Tunisia  x  Australia :  [-4.27232771e+12  3.85688423e+12] - [nan nan]  ...................  output (weighted):  [-8.12921194e+12 -4.27232771e+12] [nan nan]    original:  [-8.12921194e+12 -4.27232771e+12] [nan nan]\n",
      "Poland  x  Saudi Arabia :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "France  x  Denmark :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Argentina  x  Mexico :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Japan  x  Costa Rica :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Belgium  x  Morocco :  [-3.15943677e+12  2.85221141e+12] - [nan nan]  ...................  output (weighted):  [-6.01164818e+12 -3.15943677e+12] [nan nan]    original:  [-6.01164818e+12 -3.15943677e+12] [nan nan]\n",
      "Croatia  x  Canada :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Spain  x  Germany :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Cameroon  x  Serbia :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "South Korea  x  Ghana :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Brazil  x  Switzerland :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Portugal  x  Uruguay :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Ecuador  x  Senegal :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Netherlands  x  Qatar :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Wales  x  England :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Iran  x  United States :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Australia  x  Denmark :  [ 1.40193743e+13 -1.26561227e+13] - [nan nan]  ...................  output (weighted):  [2.66754969e+13 1.40193743e+13] [nan nan]    original:  [2.66754969e+13 1.40193743e+13] [nan nan]\n",
      "Tunisia  x  France :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Poland  x  Argentina :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Saudi Arabia  x  Mexico :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Croatia  x  Belgium :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Canada  x  Morocco :  [-3.15943677e+12  2.85221141e+12] - [nan nan]  ...................  output (weighted):  [-6.01164818e+12 -3.15943677e+12] [nan nan]    original:  [-6.01164818e+12 -3.15943677e+12] [nan nan]\n",
      "Japan  x  Spain :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Costa Rica  x  Germany :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Ghana  x  Uruguay :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "South Korea  x  Portugal :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Serbia  x  Switzerland :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "Cameroon  x  Brazil :  [-3.60282176e+12  3.25248140e+12] - [nan nan]  ...................  output (weighted):  [-6.85530316e+12 -3.60282176e+12] [nan nan]    original:  [-6.85530316e+12 -3.60282176e+12] [nan nan]\n",
      "MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bmk1bj\\.conda\\envs\\aimatch\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1607: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample weights unused\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bmk1bj\\.conda\\envs\\aimatch\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1607: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample weights unused\n",
      "MLP\n",
      "851 / 2068  - 1.65 points per match\n",
      "Val:\n",
      "Uruguay  x  Chile :  [0.79829348 1.36447032] - [0. 1.]  ...................  output (weighted):  [-0.56617685  0.79829348] [0. 1.]    original:  [-0.56617685  0.79829348] [0. 1.]\n",
      "Argentina  x  Paraguay :  [ 0.8729937  -0.22631425] - [1. 1.]  ...................  output (weighted):  [1.09930794 0.8729937 ] [1. 1.]    original:  [1.09930794 0.8729937 ] [1. 1.]\n",
      "Scotland  x  Croatia :  [3.91547162 6.36203366] - [-2.  3.]  ...................  output (weighted):  [-2.44656204  3.91547162] [-2.  3.]    original:  [-2.44656204  3.91547162] [-2.  3.]\n",
      "England  x  Czech Republic :  [ 1.20071166 -0.84525228] - [1. 1.]  ...................  output (weighted):  [2.04596394 1.20071166] [1. 1.]    original:  [2.04596394 1.20071166] [1. 1.]\n",
      "Spain  x  Slovakia :  [2.69520412 0.25901056] - [5. 5.]  ...................  output (weighted):  [2.43619356 2.69520412] [5. 5.]    original:  [2.43619356 2.69520412] [5. 5.]\n",
      "Sweden  x  Poland :  [1.68695285 2.48444826] - [1. 3.]  ...................  output (weighted):  [-0.79749541  1.68695285] [1. 3.]    original:  [-0.79749541  1.68695285] [1. 3.]\n",
      "Germany  x  Hungary :  [2.62435187 0.69217456] - [0. 2.]  ...................  output (weighted):  [1.93217731 2.62435187] [0. 2.]    original:  [1.93217731 2.62435187] [0. 2.]\n",
      "Portugal  x  France :  [1.8905466  1.77490382] - [0. 2.]  ...................  output (weighted):  [0.11564277 1.8905466 ] [0. 2.]    original:  [0.11564277 1.8905466 ] [0. 2.]\n",
      "Ecuador  x  Peru :  [3.05864649 3.70842861] - [0. 2.]  ...................  output (weighted):  [-0.64978212  3.05864649] [0. 2.]    original:  [-0.64978212  3.05864649] [0. 2.]\n",
      "Brazil  x  Colombia :  [ 2.3526814  -1.12278707] - [1. 2.]  ...................  output (weighted):  [3.47546847 2.3526814 ] [1. 2.]    original:  [3.47546847 2.3526814 ] [1. 2.]\n",
      "Bolivia  x  Uruguay :  [2.28934389 3.17282763] - [-2.  2.]  ...................  output (weighted):  [-0.88348373  2.28934389] [-2.  2.]    original:  [-0.88348373  2.28934389] [-2.  2.]\n",
      "Wales  x  Denmark :  [-0.04289384  1.54197204] - [-4.  4.]  ...................  output (weighted):  [-1.58486588 -0.04289384] [-4.  4.]    original:  [-1.58486588 -0.04289384] [-4.  4.]\n",
      "Netherlands  x  Czech Republic :  [1.25764188 0.71566909] - [-2.  2.]  ...................  output (weighted):  [0.54197279 1.25764188] [-2.  2.]    original:  [0.54197279 1.25764188] [-2.  2.]\n",
      "Belgium  x  Portugal :  [4.03408286 3.10863973] - [1. 1.]  ...................  output (weighted):  [0.92544314 4.03408286] [1. 1.]    original:  [0.92544314 4.03408286] [1. 1.]\n",
      "Brazil  x  Ecuador :  [ 1.53847496 -0.27925988] - [0. 1.]  ...................  output (weighted):  [1.81773483 1.53847496] [0. 1.]    original:  [1.81773483 1.53847496] [0. 1.]\n",
      "Croatia  x  Spain :  [0.66339308 1.47867227] - [-2.  5.]  ...................  output (weighted):  [-0.81527919  0.66339308] [-2.  5.]    original:  [-0.81527919  0.66339308] [-2.  5.]\n",
      "France  x  Switzerland :  [1.41283699 1.59421603] - [0. 3.]  ...................  output (weighted):  [-0.18137904  1.41283699] [0. 3.]    original:  [-0.18137904  1.41283699] [0. 3.]\n",
      "Argentina  x  Bolivia :  [ 2.57175795 -0.99704227] - [3. 4.]  ...................  output (weighted):  [3.56880022 2.57175795] [3. 4.]    original:  [3.56880022 2.57175795] [3. 4.]\n",
      "Uruguay  x  Paraguay :  [0.5615598  0.28654829] - [1. 1.]  ...................  output (weighted):  [0.27501152 0.5615598 ] [1. 1.]    original:  [0.27501152 0.5615598 ] [1. 1.]\n",
      "England  x  Germany :  [2.5814238 1.064853 ] - [2. 2.]  ...................  output (weighted):  [1.5165708 2.5814238] [2. 2.]    original:  [1.5165708 2.5814238] [2. 2.]\n",
      "Mexico  x  Panama :  [1.8552717  1.13557198] - [3. 3.]  ...................  output (weighted):  [0.71969971 1.8552717 ] [3. 3.]    original:  [0.71969971 1.8552717 ] [3. 3.]\n",
      "Switzerland  x  Spain :  [0.17850753 1.01871087] - [0. 1.]  ...................  output (weighted):  [-0.84020335  0.17850753] [0. 1.]    original:  [-0.84020335  0.17850753] [0. 1.]\n",
      "Belgium  x  Italy :  [2.69480905 1.89987742] - [-1.  2.]  ...................  output (weighted):  [0.79493164 2.69480905] [-1.  2.]    original:  [0.79493164 2.69480905] [-1.  2.]\n",
      "Brazil  x  Chile :  [1.15200984 0.15631621] - [1. 1.]  ...................  output (weighted):  [0.99569363 1.15200984] [1. 1.]    original:  [0.99569363 1.15200984] [1. 1.]\n",
      "Czech Republic  x  Denmark :  [1.21083418 0.67130756] - [-1.  2.]  ...................  output (weighted):  [0.53952662 1.21083418] [-1.  2.]    original:  [0.53952662 1.21083418] [-1.  2.]\n",
      "Ukraine  x  England :  [0.83509217 2.15969372] - [-4.  4.]  ...................  output (weighted):  [-1.32460155  0.83509217] [-4.  4.]    original:  [-1.32460155  0.83509217] [-4.  4.]\n",
      "Mexico  x  Nigeria :  [0.21229599 1.34890985] - [4. 4.]  ...................  output (weighted):  [-1.13661386  0.21229599] [4. 4.]    original:  [-1.13661386  0.21229599] [4. 4.]\n",
      "Uruguay  x  Colombia :  [1.99896503 0.08536704] - [0. 0.]  ...................  output (weighted):  [1.91359799 1.99896503] [0. 0.]    original:  [1.91359799 1.99896503] [0. 0.]\n",
      "Argentina  x  Ecuador :  [1.49619249 0.4160317 ] - [3. 3.]  ...................  output (weighted):  [1.08016078 1.49619249] [3. 3.]    original:  [1.08016078 1.49619249] [3. 3.]\n",
      "Qatar  x  El Salvador :  [4.62615747 0.60351143] - [1. 1.]  ...................  output (weighted):  [4.02264603 4.62615747] [1. 1.]    original:  [4.02264603 4.62615747] [1. 1.]\n",
      "Brazil  x  Peru :  [1.95358516 0.21366422] - [1. 1.]  ...................  output (weighted):  [1.73992094 1.95358516] [1. 1.]    original:  [1.73992094 1.95358516] [1. 1.]\n",
      "Argentina  x  Colombia :  [ 2.31039893 -0.42749549] - [0. 1.]  ...................  output (weighted):  [2.73789442 2.31039893] [0. 1.]    original:  [2.73789442 2.31039893] [0. 1.]\n",
      "Italy  x  Spain :  [1.05311974 0.54938934] - [0. 1.]  ...................  output (weighted):  [0.50373041 1.05311974] [0. 1.]    original:  [0.50373041 1.05311974] [0. 1.]\n",
      "England  x  Denmark :  [1.26749968 0.91792934] - [1. 2.]  ...................  output (weighted):  [0.34957035 1.26749968] [1. 2.]    original:  [0.34957035 1.26749968] [1. 2.]\n",
      "Senegal  x  Namibia :  [2.48122882 0.4067347 ] - [-1.  2.]  ...................  output (weighted):  [2.07449411 2.48122882] [-1.  2.]    original:  [2.07449411 2.48122882] [-1.  2.]\n",
      "Senegal  x  Mozambique :  [2.48407708 0.40525201] - [1. 1.]  ...................  output (weighted):  [2.07882508 2.48407708] [1. 1.]    original:  [2.07882508 2.48407708] [1. 1.]\n",
      "Brazil  x  Argentina :  [2.17465329 1.87063379] - [-1.  1.]  ...................  output (weighted):  [0.3040195  2.17465329] [-1.  1.]    original:  [0.3040195  2.17465329] [-1.  1.]\n",
      "Mexico  x  Trinidad and Tobago :  [ 3.11783608 -0.16367417] - [0. 0.]  ...................  output (weighted):  [3.28151024 3.11783608] [0. 0.]    original:  [3.28151024 3.11783608] [0. 0.]\n",
      "England  x  Italy :  [0.71765355 0.58792959] - [0. 1.]  ...................  output (weighted):  [0.12972396 0.71765355] [0. 1.]    original:  [0.12972396 0.71765355] [0. 1.]\n",
      "Canada  x  Martinique :  [2.43329896 0.13749512] - [3. 4.]  ...................  output (weighted):  [2.29580385 2.43329896] [3. 4.]    original:  [2.29580385 2.43329896] [3. 4.]\n",
      "United States  x  Haiti :  [4.03143155 0.14420872] - [1. 1.]  ...................  output (weighted):  [3.88722283 4.03143155] [1. 1.]    original:  [3.88722283 4.03143155] [1. 1.]\n",
      "Costa Rica  x  Guadeloupe :  [1.51735718 1.78349873] - [2. 3.]  ...................  output (weighted):  [-0.26614156  1.51735718] [2. 3.]    original:  [-0.26614156  1.51735718] [2. 3.]\n",
      "Senegal  x  Zimbabwe :  [2.47990018 0.39659058] - [1. 2.]  ...................  output (weighted):  [2.0833096  2.47990018] [1. 2.]    original:  [2.0833096  2.47990018] [1. 2.]\n",
      "Qatar  x  Panama :  [2.93118655 1.4285848 ] - [0. 3.]  ...................  output (weighted):  [1.50260175 2.93118655] [0. 3.]    original:  [1.50260175 2.93118655] [0. 3.]\n",
      "Senegal  x  Malawi :  [2.48225617 0.41709508] - [1. 2.]  ...................  output (weighted):  [2.06516109 2.48225617] [1. 2.]    original:  [2.06516109 2.48225617] [1. 2.]\n",
      "Guatemala  x  Mexico :  [2.43068795 3.91935207] - [-3.  3.]  ...................  output (weighted):  [-1.48866412  2.43068795] [-3.  3.]    original:  [-1.48866412  2.43068795] [-3.  3.]\n",
      "Haiti  x  Canada :  [1.32371288 2.20055222] - [-3.  4.]  ...................  output (weighted):  [-0.87683934  1.32371288] [-3.  4.]    original:  [-0.87683934  1.32371288] [-3.  4.]\n",
      "United States  x  Martinique :  [3.93484331 0.56821188] - [5. 6.]  ...................  output (weighted):  [3.36663143 3.93484331] [5. 6.]    original:  [3.36663143 3.93484331] [5. 6.]\n",
      "Test:\n",
      "Qatar  x  Ecuador :  [0.83436015 0.54463519] - [0. 2.]  ...................  output (weighted):  [0.28972496 0.83436015] [0. 2.]    original:  [0.28972496 0.83436015] [0. 2.]\n",
      "England  x  Iran :  [1.94375834 3.216888  ] - [6. 2.]  ...................  output (weighted):  [-1.27312966  1.94375834] [6. 2.]    original:  [-1.27312966  1.94375834] [6. 2.]\n",
      "Senegal  x  Netherlands :  [1.04831893 1.41375333] - [0. 2.]  ...................  output (weighted):  [-0.3654344   1.04831893] [0. 2.]    original:  [-0.3654344   1.04831893] [0. 2.]\n",
      "United States  x  Wales :  [1.88092971 0.63797526] - [1. 1.]  ...................  output (weighted):  [1.24295445 1.88092971] [1. 1.]    original:  [1.24295445 1.88092971] [1. 1.]\n",
      "Argentina  x  Saudi Arabia :  [0.84918215 1.1847968 ] - [1. 2.]  ...................  output (weighted):  [-0.33561465  0.84918215] [1. 2.]    original:  [-0.33561465  0.84918215] [1. 2.]\n",
      "Denmark  x  Tunisia :  [ 0.17865191 -0.98356479] - [0. 0.]  ...................  output (weighted):  [1.16221671 0.17865191] [0. 0.]    original:  [1.16221671 0.17865191] [0. 0.]\n",
      "Mexico  x  Poland :  [0.38591616 1.17818514] - [0. 0.]  ...................  output (weighted):  [-0.79226898  0.38591616] [0. 0.]    original:  [-0.79226898  0.38591616] [0. 0.]\n",
      "France  x  Australia :  [2.62127011 3.66848248] - [4. 1.]  ...................  output (weighted):  [-1.04721237  2.62127011] [4. 1.]    original:  [-1.04721237  2.62127011] [4. 1.]\n",
      "Morocco  x  Croatia :  [1.95793665 1.20418738] - [0. 0.]  ...................  output (weighted):  [0.75374927 1.95793665] [0. 0.]    original:  [0.75374927 1.95793665] [0. 0.]\n",
      "Germany  x  Japan :  [1.16635021 0.13695745] - [1. 2.]  ...................  output (weighted):  [1.02939276 1.16635021] [1. 2.]    original:  [1.02939276 1.16635021] [1. 2.]\n",
      "Spain  x  Costa Rica :  [ 0.67104083 -1.09589416] - [7. 0.]  ...................  output (weighted):  [1.76693499 0.67104083] [7. 0.]    original:  [1.76693499 0.67104083] [7. 0.]\n",
      "Belgium  x  Canada :  [3.13985374 0.79585814] - [1. 0.]  ...................  output (weighted):  [2.3439956  3.13985374] [1. 0.]    original:  [2.3439956  3.13985374] [1. 0.]\n",
      "Switzerland  x  Cameroon :  [-1.73499229 -1.00747766] - [1. 0.]  ...................  output (weighted):  [-0.72751463 -1.73499229] [1. 0.]    original:  [-0.72751463 -1.73499229] [1. 0.]\n",
      "Uruguay  x  South Korea :  [ 1.86314367 -0.47943183] - [0. 0.]  ...................  output (weighted):  [2.34257549 1.86314367] [0. 0.]    original:  [2.34257549 1.86314367] [0. 0.]\n",
      "Portugal  x  Ghana :  [ 0.78861926 -0.39023578] - [3. 2.]  ...................  output (weighted):  [1.17885504 0.78861926] [3. 2.]    original:  [1.17885504 0.78861926] [3. 2.]\n",
      "Brazil  x  Serbia :  [ 0.20288462 -1.41246499] - [3. 2.]  ...................  output (weighted):  [1.61534961 0.20288462] [3. 2.]    original:  [1.61534961 0.20288462] [3. 2.]\n",
      "Wales  x  Iran :  [0.40893082 2.95843594] - [0. 2.]  ...................  output (weighted):  [-2.54950512  0.40893082] [0. 2.]    original:  [-2.54950512  0.40893082] [0. 2.]\n",
      "Qatar  x  Senegal :  [1.06134885 0.70136332] - [nan nan]  ...................  output (weighted):  [0.35998552 1.06134885] [nan nan]    original:  [0.35998552 1.06134885] [nan nan]\n",
      "Netherlands  x  Ecuador :  [0.93111808 1.33989284] - [nan nan]  ...................  output (weighted):  [-0.40877476  0.93111808] [nan nan]    original:  [-0.40877476  0.93111808] [nan nan]\n",
      "England  x  United States :  [2.30378686 1.60873058] - [nan nan]  ...................  output (weighted):  [0.69505628 2.30378686] [nan nan]    original:  [0.69505628 2.30378686] [nan nan]\n",
      "Tunisia  x  Australia :  [3.25866719 3.99497221] - [nan nan]  ...................  output (weighted):  [-0.73630502  3.25866719] [nan nan]    original:  [-0.73630502  3.25866719] [nan nan]\n",
      "Poland  x  Saudi Arabia :  [0.42765047 2.51149783] - [nan nan]  ...................  output (weighted):  [-2.08384736  0.42765047] [nan nan]    original:  [-2.08384736  0.42765047] [nan nan]\n",
      "France  x  Denmark :  [0.35002414 1.44819191] - [nan nan]  ...................  output (weighted):  [-1.09816778  0.35002414] [nan nan]    original:  [-1.09816778  0.35002414] [nan nan]\n",
      "Argentina  x  Mexico :  [1.21421057 0.5096986 ] - [nan nan]  ...................  output (weighted):  [0.70451197 1.21421057] [nan nan]    original:  [0.70451197 1.21421057] [nan nan]\n",
      "Japan  x  Costa Rica :  [0.99357499 0.21630979] - [nan nan]  ...................  output (weighted):  [0.7772652  0.99357499] [nan nan]    original:  [0.7772652  0.99357499] [nan nan]\n",
      "Belgium  x  Morocco :  [2.80456066 0.97396344] - [nan nan]  ...................  output (weighted):  [1.83059722 2.80456066] [nan nan]    original:  [1.83059722 2.80456066] [nan nan]\n",
      "Croatia  x  Canada :  [0.89606031 0.81825493] - [nan nan]  ...................  output (weighted):  [0.07780538 0.89606031] [nan nan]    original:  [0.07780538 0.89606031] [nan nan]\n",
      "Spain  x  Germany :  [2.05424046 0.55931217] - [nan nan]  ...................  output (weighted):  [1.49492829 2.05424046] [nan nan]    original:  [1.49492829 2.05424046] [nan nan]\n",
      "Cameroon  x  Serbia :  [-1.50606304 -1.60150579] - [nan nan]  ...................  output (weighted):  [ 0.09544275 -1.50606304] [nan nan]    original:  [ 0.09544275 -1.50606304] [nan nan]\n",
      "South Korea  x  Ghana :  [-0.55115526  0.61380358] - [nan nan]  ...................  output (weighted):  [-1.16495884 -0.55115526] [nan nan]    original:  [-1.16495884 -0.55115526] [nan nan]\n",
      "Brazil  x  Switzerland :  [ 0.76171982 -0.53260839] - [nan nan]  ...................  output (weighted):  [1.29432821 0.76171982] [nan nan]    original:  [1.29432821 0.76171982] [nan nan]\n",
      "Portugal  x  Uruguay :  [1.92915883 1.10404   ] - [nan nan]  ...................  output (weighted):  [0.82511883 1.92915883] [nan nan]    original:  [0.82511883 1.92915883] [nan nan]\n",
      "Ecuador  x  Senegal :  [2.05142038 2.56529089] - [nan nan]  ...................  output (weighted):  [-0.51387051  2.05142038] [nan nan]    original:  [-0.51387051  2.05142038] [nan nan]\n",
      "Netherlands  x  Qatar :  [ 1.71409934 -0.95542966] - [nan nan]  ...................  output (weighted):  [2.66952899 1.71409934] [nan nan]    original:  [2.66952899 1.71409934] [nan nan]\n",
      "Wales  x  England :  [-1.06865669  0.95585711] - [nan nan]  ...................  output (weighted):  [-2.0245138  -1.06865669] [nan nan]    original:  [-2.0245138  -1.06865669] [nan nan]\n",
      "Iran  x  United States :  [3.07945138 2.08727582] - [nan nan]  ...................  output (weighted):  [0.99217556 3.07945138] [nan nan]    original:  [0.99217556 3.07945138] [nan nan]\n",
      "Australia  x  Denmark :  [1.35790936 1.35616929] - [nan nan]  ...................  output (weighted):  [0.00174007 1.35790936] [nan nan]    original:  [0.00174007 1.35790936] [nan nan]\n",
      "Tunisia  x  France :  [0.69964399 1.80116296] - [nan nan]  ...................  output (weighted):  [-1.10151897  0.69964399] [nan nan]    original:  [-1.10151897  0.69964399] [nan nan]\n",
      "Poland  x  Argentina :  [0.89173454 3.08568465] - [nan nan]  ...................  output (weighted):  [-2.1939501   0.89173454] [nan nan]    original:  [-2.1939501   0.89173454] [nan nan]\n",
      "Saudi Arabia  x  Mexico :  [1.248077   2.56001478] - [nan nan]  ...................  output (weighted):  [-1.31193778  1.248077  ] [nan nan]    original:  [-1.31193778  1.248077  ] [nan nan]\n",
      "Croatia  x  Belgium :  [0.5580082  2.76254626] - [nan nan]  ...................  output (weighted):  [-2.20453806  0.5580082 ] [nan nan]    original:  [-2.20453806  0.5580082 ] [nan nan]\n",
      "Canada  x  Morocco :  [0.68932906 0.27571562] - [nan nan]  ...................  output (weighted):  [0.41361344 0.68932906] [nan nan]    original:  [0.41361344 0.68932906] [nan nan]\n",
      "Japan  x  Spain :  [0.72538182 0.95099078] - [nan nan]  ...................  output (weighted):  [-0.22560896  0.72538182] [nan nan]    original:  [-0.22560896  0.72538182] [nan nan]\n",
      "Costa Rica  x  Germany :  [0.70876719 2.51794489] - [nan nan]  ...................  output (weighted):  [-1.8091777   0.70876719] [nan nan]    original:  [-1.8091777   0.70876719] [nan nan]\n",
      "Ghana  x  Uruguay :  [2.32717045 2.46158263] - [nan nan]  ...................  output (weighted):  [-0.13441218  2.32717045] [nan nan]    original:  [-0.13441218  2.32717045] [nan nan]\n",
      "South Korea  x  Portugal :  [0.80887237 2.82428267] - [nan nan]  ...................  output (weighted):  [-2.01541031  0.80887237] [nan nan]    original:  [-2.01541031  0.80887237] [nan nan]\n",
      "Serbia  x  Switzerland :  [0.5172964  1.51648086] - [nan nan]  ...................  output (weighted):  [-0.99918446  0.5172964 ] [nan nan]    original:  [-0.99918446  0.5172964 ] [nan nan]\n",
      "Cameroon  x  Brazil :  [0.91999266 3.54391195] - [nan nan]  ...................  output (weighted):  [-2.62391928  0.91999266] [nan nan]    original:  [-2.62391928  0.91999266] [nan nan]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def fit_simple_regressor(X_train, Y_train, X_val, Y_val, X_test, sample_weights_train, regressor, name: str, label_weights: list, show_predicted_indexes = [0, 1], split_models=False):\n",
    "    print(name)\n",
    "    Y_val_pred, Y_test_pred = np.zeros(Y_val.shape), np.zeros((X_test.shape[0], Y_val.shape[1]))\n",
    "    \n",
    "    if split_models:\n",
    "        try:\n",
    "            regressor.fit(X_train, Y_train[:, 0].reshape(-1, 1),  sample_weight = sample_weights_train)        \n",
    "        except:\n",
    "            regressor.fit(X_train, Y_train[:, 0].reshape(-1, 1))\n",
    "            print(\"Sample weights unused\")\n",
    "            \n",
    "        Y_val_pred = regressor.predict(X_val).reshape(-1, 1)\n",
    "        Y_test_pred = regressor.predict(X_test).reshape(-1, 1)\n",
    "        \n",
    "        try:\n",
    "            regressor.fit(X_train, Y_train[:, 1].reshape(-1, 1),  sample_weight = sample_weights_train)        \n",
    "        except:\n",
    "            regressor.fit(X_train, Y_train[:, 1].reshape(-1, 1))\n",
    "            print(\"Sample weights unused\")\n",
    "        Y_val_pred = np.hstack((Y_val_pred, regressor.predict(X_val).reshape(-1, 1)))\n",
    "        Y_test_pred = np.hstack((Y_test_pred, regressor.predict(X_test).reshape(-1, 1)))\n",
    "        \n",
    "    else:\n",
    "        try:\n",
    "            regressor.fit(X_train, Y_train,  sample_weight = sample_weights_train)        \n",
    "        except:\n",
    "            regressor.fit(X_train, Y_train)\n",
    "            print(\"Sample weights unused\")\n",
    "        \n",
    "        Y_val_pred = regressor.predict(X_val)\n",
    "        Y_test_pred = regressor.predict(X_test)\n",
    "        \n",
    "        \n",
    "    reg_score = score(np.round(Y_val_pred), Y_val, label_weights=label_weights)\n",
    "    print(name)\n",
    "    print(reg_score, \"/\", max_score, \" - %s points per match\" % (np.round(reg_score/len(Y_val), 2)))\n",
    "    \n",
    "    print(\"Val:\")\n",
    "    show_predictions(dataset, X_val, Y_val, Y_val_pred, show_predicted_indexes, label_weights)\n",
    "    print(\"Test:\")\n",
    "    Y_test = np.hstack((np.vstack(results_df.home_score), np.vstack(results_df.away_score)))\n",
    "    show_predictions(dataset, X_test, Y_test, Y_test_pred, show_predicted_indexes, label_weights)\n",
    "    \n",
    "\n",
    "models = {\n",
    "    #\"Tree\": DecisionTreeRegressor(random_state=0),\n",
    "    \"Linear\": LinearRegression(),\n",
    "    \"MLP\": MLPRegressor(hidden_layer_sizes = (128, 32, 8), activation=\"identity\")\n",
    "}\n",
    "\n",
    "show_predicted_indexes = [i for i in range(0, len(X_test))]\n",
    "trainable = 0.1\n",
    "start = int((1 - trainable) * len(X_train))\n",
    "for name, model in models. items():\n",
    "    fit_simple_regressor(X_train[start:], Y_train[start:], X_val, Y_val, X_test,\n",
    "                         sample_weights_train[start:], model, name, \n",
    "                         show_predicted_indexes = show_predicted_indexes, label_weights=dataset.label_weights,\n",
    "                         split_models = True\n",
    "                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  2.]\n",
      " [ 6.  2.]\n",
      " [ 0.  2.]\n",
      " [ 1.  1.]\n",
      " [ 1.  2.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 4.  1.]\n",
      " [ 0.  0.]\n",
      " [ 1.  2.]\n",
      " [ 7.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  0.]\n",
      " [ 3.  2.]\n",
      " [ 3.  2.]\n",
      " [ 0.  2.]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n"
     ]
    }
   ],
   "source": [
    "print(np.hstack((np.vstack(results_df.home_score), np.vstack(results_df.away_score))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model, save_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scorer(Callback):\n",
    "    def __init__(self, X, Y, label_weights):\n",
    "        self.X_val, self.Y_val = X, Y\n",
    "        self.label_weights = label_weights\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        Y_pred = np.hstack(self.model.predict(self.X_val))\n",
    "\n",
    "        print(\"X_val score = \", score(Y_pred, self.Y_val, label_weights=self.label_weights))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bmk1bj\\.conda\\envs\\aimatch\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_input = Input(shape=(X_train.shape[1],)) \n",
    "# First branch\n",
    "a_dense_1 = Dense(128, activation = \"relu\")(model_input)\n",
    "a_dense_2 = Dense(32, activation = \"relu\")(a_dense_1)\n",
    "a_dense_3 = Dense(8, activation = \"relu\")(a_dense_2)\n",
    "a_dense_4 = Dense(1, name = \"goal_diff\", activation = \"linear\")(a_dense_2)\n",
    "# Second branch\n",
    "b_dense_1 = Dense(128, activation = \"relu\")(model_input)\n",
    "b_dense_2 = Dense(32, activation = \"relu\")(b_dense_1)\n",
    "b_dense_3 = Dense(8, activation = \"relu\")(b_dense_2)\n",
    "b_dense_4 = Dense(1, name = \"winner_goals\", activation = \"relu\")(b_dense_1)\n",
    "\n",
    "model = Model(model_input, outputs=[a_dense_4, b_dense_4])\n",
    "\n",
    "optimizer = SGD(lr=0.02)\n",
    "model.compile(optimizer=optimizer,loss={'goal_diff': 'mse', 'winner_goals': 'mae'}, metrics={'goal_diff': 'mse', 'winner_goals': 'mae'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "174/174 [==============================] - 0s 925us/steps: 5.6785 - goal_diff_loss: 4.1392 - winner_goals_loss: 1.5394 - goal_diff_mse: 4.1392 - winner_goals_mae\n",
      "X_val score =  9174\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.6722 - goal_diff_loss: 4.1348 - winner_goals_loss: 1.5374 - goal_diff_mse: 4.1348 - winner_goals_mae: 1.5374 - val_loss: 5.3962 - val_goal_diff_loss: 3.9601 - val_winner_goals_loss: 1.4361 - val_goal_diff_mse: 3.9601 - val_winner_goals_mae: 1.4361\n",
      "Epoch 2/17\n",
      "174/174 [==============================] - 0s 922us/steps: 5.6305 - goal_diff_loss: 4.0971 - winner_goals_loss: 1.5334 - goal_diff_mse: 4.0971 - winner_goals_mae\n",
      "X_val score =  9247\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.6158 - goal_diff_loss: 4.0843 - winner_goals_loss: 1.5316 - goal_diff_mse: 4.0843 - winner_goals_mae: 1.5316 - val_loss: 5.3793 - val_goal_diff_loss: 3.9368 - val_winner_goals_loss: 1.4426 - val_goal_diff_mse: 3.9368 - val_winner_goals_mae: 1.4426\n",
      "Epoch 3/17\n",
      "174/174 [==============================] - 0s 902us/steps: 5.6017 - goal_diff_loss: 4.0710 - winner_goals_loss: 1.5307 - goal_diff_mse: 4.0710 - winner_goals_mae\n",
      "X_val score =  9324\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.5804 - goal_diff_loss: 4.0533 - winner_goals_loss: 1.5271 - goal_diff_mse: 4.0533 - winner_goals_mae: 1.5271 - val_loss: 5.2626 - val_goal_diff_loss: 3.8237 - val_winner_goals_loss: 1.4389 - val_goal_diff_mse: 3.8237 - val_winner_goals_mae: 1.4389\n",
      "Epoch 4/17\n",
      "174/174 [==============================] - 0s 939us/steps: 5.5275 - goal_diff_loss: 4.0063 - winner_goals_loss: 1.5212 - goal_diff_mse: 4.0063 - winner_goals_mae\n",
      "X_val score =  9257\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.5456 - goal_diff_loss: 4.0222 - winner_goals_loss: 1.5233 - goal_diff_mse: 4.0222 - winner_goals_mae: 1.5233 - val_loss: 5.3589 - val_goal_diff_loss: 3.9266 - val_winner_goals_loss: 1.4322 - val_goal_diff_mse: 3.9266 - val_winner_goals_mae: 1.4322\n",
      "Epoch 5/17\n",
      "174/174 [==============================] - 0s 1ms/steposs: 5.5473 - goal_diff_loss: 4.0232 - winner_goals_loss: 1.5241 - goal_diff_mse: 4.0232 - winner_goals_mae\n",
      "X_val score =  9376\n",
      "811/811 [==============================] - 2s 2ms/step - loss: 5.5179 - goal_diff_loss: 3.9988 - winner_goals_loss: 1.5191 - goal_diff_mse: 3.9988 - winner_goals_mae: 1.5191 - val_loss: 5.1640 - val_goal_diff_loss: 3.7344 - val_winner_goals_loss: 1.4296 - val_goal_diff_mse: 3.7344 - val_winner_goals_mae: 1.4296\n",
      "Epoch 6/17\n",
      "174/174 [==============================] - 0s 947us/steps: 5.4792 - goal_diff_loss: 3.9648 - winner_goals_loss: 1.5144 - goal_diff_mse: 3.9648 - winner_goals_mae\n",
      "X_val score =  9504\n",
      "811/811 [==============================] - 2s 2ms/step - loss: 5.4809 - goal_diff_loss: 3.9649 - winner_goals_loss: 1.5160 - goal_diff_mse: 3.9649 - winner_goals_mae: 1.5160 - val_loss: 5.2316 - val_goal_diff_loss: 3.8026 - val_winner_goals_loss: 1.4290 - val_goal_diff_mse: 3.8026 - val_winner_goals_mae: 1.4290\n",
      "Epoch 7/17\n",
      "174/174 [==============================] - 0s 990us/steps: 5.4664 - goal_diff_loss: 3.9519 - winner_goals_loss: 1.5145 - goal_diff_mse: 3.9519 - winner_goals_mae\n",
      "X_val score =  9340\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.4585 - goal_diff_loss: 3.9453 - winner_goals_loss: 1.5132 - goal_diff_mse: 3.9453 - winner_goals_mae: 1.5132 - val_loss: 5.1520 - val_goal_diff_loss: 3.7268 - val_winner_goals_loss: 1.4252 - val_goal_diff_mse: 3.7268 - val_winner_goals_mae: 1.4252\n",
      "Epoch 8/17\n",
      "174/174 [==============================] - 0s 907us/steps: 5.4498 - goal_diff_loss: 3.9363 - winner_goals_loss: 1.5135 - goal_diff_mse: 3.9363 - winner_goals_mae\n",
      "X_val score =  9444\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.4331 - goal_diff_loss: 3.9227 - winner_goals_loss: 1.5104 - goal_diff_mse: 3.9227 - winner_goals_mae: 1.5104 - val_loss: 5.1530 - val_goal_diff_loss: 3.7258 - val_winner_goals_loss: 1.4271 - val_goal_diff_mse: 3.7258 - val_winner_goals_mae: 1.4271\n",
      "Epoch 9/17\n",
      "174/174 [==============================] - 0s 948us/steps: 5.3947 - goal_diff_loss: 3.8872 - winner_goals_loss: 1.5074 - goal_diff_mse: 3.8872 - winner_goals_mae\n",
      "X_val score =  9458\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.4016 - goal_diff_loss: 3.8948 - winner_goals_loss: 1.5068 - goal_diff_mse: 3.8948 - winner_goals_mae: 1.5068 - val_loss: 5.2603 - val_goal_diff_loss: 3.8332 - val_winner_goals_loss: 1.4271 - val_goal_diff_mse: 3.8332 - val_winner_goals_mae: 1.4271\n",
      "Epoch 10/17\n",
      "174/174 [==============================] - 0s 1ms/steposs: 5.3666 - goal_diff_loss: 3.8640 - winner_goals_loss: 1.5026 - goal_diff_mse: 3.8640 - winner_goals_mae\n",
      "X_val score =  9306\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.3784 - goal_diff_loss: 3.8745 - winner_goals_loss: 1.5039 - goal_diff_mse: 3.8745 - winner_goals_mae: 1.5039 - val_loss: 5.3490 - val_goal_diff_loss: 3.9231 - val_winner_goals_loss: 1.4259 - val_goal_diff_mse: 3.9231 - val_winner_goals_mae: 1.4259\n",
      "Epoch 11/17\n",
      "174/174 [==============================] - 0s 947us/steps: 5.3634 - goal_diff_loss: 3.8620 - winner_goals_loss: 1.5014 - goal_diff_mse: 3.8620 - winner_goals_mae\n",
      "X_val score =  9176\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.3626 - goal_diff_loss: 3.8609 - winner_goals_loss: 1.5017 - goal_diff_mse: 3.8609 - winner_goals_mae: 1.5017 - val_loss: 5.6172 - val_goal_diff_loss: 4.1828 - val_winner_goals_loss: 1.4344 - val_goal_diff_mse: 4.1828 - val_winner_goals_mae: 1.4344\n",
      "Epoch 12/17\n",
      "174/174 [==============================] - 0s 951us/steps: 5.3340 - goal_diff_loss: 3.8352 - winner_goals_loss: 1.4988 - goal_diff_mse: 3.8352 - winner_goals_mae\n",
      "X_val score =  9405\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.3356 - goal_diff_loss: 3.8363 - winner_goals_loss: 1.4994 - goal_diff_mse: 3.8363 - winner_goals_mae: 1.4994 - val_loss: 5.2061 - val_goal_diff_loss: 3.7798 - val_winner_goals_loss: 1.4263 - val_goal_diff_mse: 3.7798 - val_winner_goals_mae: 1.4263\n",
      "Epoch 13/17\n",
      "174/174 [==============================] - 0s 904us/steps: 5.3185 - goal_diff_loss: 3.8211 - winner_goals_loss: 1.4973 - goal_diff_mse: 3.8211 - winner_goals_mae\n",
      "X_val score =  9251\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.3199 - goal_diff_loss: 3.8237 - winner_goals_loss: 1.4962 - goal_diff_mse: 3.8237 - winner_goals_mae: 1.4962 - val_loss: 5.3156 - val_goal_diff_loss: 3.8633 - val_winner_goals_loss: 1.4523 - val_goal_diff_mse: 3.8633 - val_winner_goals_mae: 1.4523\n",
      "Epoch 14/17\n",
      "174/174 [==============================] - 0s 907us/steps: 5.3045 - goal_diff_loss: 3.8078 - winner_goals_loss: 1.4967 - goal_diff_mse: 3.8078 - winner_goals_mae\n",
      "X_val score =  9428\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.2955 - goal_diff_loss: 3.8003 - winner_goals_loss: 1.4952 - goal_diff_mse: 3.8003 - winner_goals_mae: 1.4952 - val_loss: 5.2044 - val_goal_diff_loss: 3.7749 - val_winner_goals_loss: 1.4295 - val_goal_diff_mse: 3.7749 - val_winner_goals_mae: 1.4295\n",
      "Epoch 15/17\n",
      "174/174 [==============================] - 0s 1ms/steposs: 5.2828 - goal_diff_loss: 3.7883 - winner_goals_loss: 1.4944 - goal_diff_mse: 3.7883 - winner_goals_mae\n",
      "X_val score =  9351\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.2813 - goal_diff_loss: 3.7893 - winner_goals_loss: 1.4920 - goal_diff_mse: 3.7893 - winner_goals_mae: 1.4920 - val_loss: 5.2754 - val_goal_diff_loss: 3.8454 - val_winner_goals_loss: 1.4300 - val_goal_diff_mse: 3.8454 - val_winner_goals_mae: 1.4300\n",
      "Epoch 16/17\n",
      "174/174 [==============================] - 0s 940us/steps: 5.2701 - goal_diff_loss: 3.7806 - winner_goals_loss: 1.4895 - goal_diff_mse: 3.7806 - winner_goals_mae\n",
      "X_val score =  9293\n",
      "811/811 [==============================] - 1s 2ms/step - loss: 5.2718 - goal_diff_loss: 3.7820 - winner_goals_loss: 1.4898 - goal_diff_mse: 3.7820 - winner_goals_mae: 1.4898 - val_loss: 5.3643 - val_goal_diff_loss: 3.9400 - val_winner_goals_loss: 1.4243 - val_goal_diff_mse: 3.9400 - val_winner_goals_mae: 1.4243\n",
      "Epoch 17/17\n",
      "174/174 [==============================] - 0s 989us/steps: 5.2538 - goal_diff_loss: 3.7656 - winner_goals_loss: 1.4882 - goal_diff_mse: 3.7656 - winner_goals_mae\n",
      "X_val score =  9412\n",
      "811/811 [==============================] - 2s 2ms/step - loss: 5.2515 - goal_diff_loss: 3.7635 - winner_goals_loss: 1.4880 - goal_diff_mse: 3.7635 - winner_goals_mae: 1.4880 - val_loss: 5.2694 - val_goal_diff_loss: 3.8401 - val_winner_goals_loss: 1.4293 - val_goal_diff_mse: 3.8401 - val_winner_goals_mae: 1.4293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4ce90f8e0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=17, batch_size=16, callbacks=[Scorer(X_val, Y_val, dataset.label_weights)], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "[[ 1.4983909   1.3967335 ]\n",
      " [ 0.93080544  1.4370933 ]\n",
      " [ 0.35802567  0.51986897]\n",
      " [ 0.36150658  0.98317933]\n",
      " [ 2.895749    1.6963801 ]\n",
      " [ 1.6186655   1.3270063 ]\n",
      " [ 0.29726958  1.2512233 ]\n",
      " [ 3.7903662   1.5981017 ]\n",
      " [-0.03740227  0.6660776 ]\n",
      " [ 1.7563066   1.593806  ]\n",
      " [ 1.586961    1.7046671 ]\n",
      " [ 0.7479663   1.3598689 ]\n",
      " [ 0.3257562   0.9505944 ]\n",
      " [ 1.8843226   0.7929591 ]\n",
      " [ 1.6551496   1.2634948 ]\n",
      " [ 2.0282583   1.6181508 ]\n",
      " [ 0.48179615  1.0961652 ]\n",
      " [ 0.9493679   0.9181212 ]\n",
      " [ 1.6722834   1.8470808 ]\n",
      " [ 1.2761515   1.7836837 ]\n",
      " [ 1.2313883   0.9348569 ]\n",
      " [ 2.333213    1.2558079 ]\n",
      " [ 0.8096037   1.7885025 ]\n",
      " [ 3.091448    1.5915183 ]\n",
      " [ 0.6172296   1.2838815 ]\n",
      " [ 0.55260324  0.97841   ]\n",
      " [ 1.0278314   1.2831444 ]\n",
      " [ 0.82484555  1.2056735 ]\n",
      " [ 0.7106583   0.7047482 ]\n",
      " [ 0.72409344  0.8212836 ]\n",
      " [ 1.4734733   2.305264  ]\n",
      " [ 1.2289196   1.0155398 ]\n",
      " [ 0.46421027  0.88693726]\n",
      " [ 3.6491055   1.8744656 ]\n",
      " [ 0.24436712  0.26062563]\n",
      " [ 0.66399586  1.7688018 ]\n",
      " [ 0.46509916  0.8841263 ]\n",
      " [ 0.27130342  0.5564598 ]\n",
      " [ 1.0848695   0.7394279 ]\n",
      " [ 0.7554295   0.94894445]\n",
      " [ 1.1238403   0.83559203]\n",
      " [ 0.09989595  0.66834486]\n",
      " [-0.16990316  0.4420021 ]\n",
      " [ 0.53871197  0.8241683 ]\n",
      " [ 0.4823761   0.50909823]\n",
      " [ 0.20693862  0.59625196]\n",
      " [ 0.7604189   1.2404778 ]\n",
      " [ 0.38900572  0.61431086]]\n",
      "174/174 [==============================] - 0s 987us/step\n"
     ]
    }
   ],
   "source": [
    "Y_test_pred = np.hstack(model.predict(X_test))\n",
    "print(Y_test_pred)\n",
    "Y_val_pred = np.hstack(model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "Morocco  x  Zimbabwe :  [2.07186627 1.04846382] - [1. 0.]  ...................  output (weighted):  [1.0234025 2.0718663] [1. 1.]    original:  [1.02340245 2.07186627] [1. 1.]\n",
      "Senegal  x  DR Congo :  [1.01010394 0.25383711] - [0. 0.]  ...................  output (weighted):  [0.75626683 1.010104  ] [0. 0.]    original:  [0.75626683 1.01010394] [0. 0.]\n",
      "Tunisia  x  Ghana :  [ 1.02262831 -0.0704391 ] - [2. 0.]  ...................  output (weighted):  [1.0930674 1.0226283] [2. 2.]    original:  [1.09306741 1.02262831] [2. 2.]\n",
      "Morocco  x  Angola :  [1.93998945 0.42680788] - [2. 2.]  ...................  output (weighted):  [1.5131816 1.9399894] [0. 2.]    original:  [1.51318157 1.93998945] [0. 2.]\n",
      "Saudi Arabia  x  Sweden :  [0.9934597  0.40741765] - [1. 1.]  ...................  output (weighted):  [0.58604205 0.9934597 ] [0. 1.]    original:  [0.58604205 0.9934597 ] [0. 1.]\n",
      "United Arab Emirates  x  South Korea :  [0.8671416 0.134148 ] - [1. 0.]  ...................  output (weighted):  [0.7329936 0.8671416] [1. 1.]    original:  [0.7329936 0.8671416] [1. 1.]\n",
      "Cameroon  x  Angola :  [1.46280742 0.33272111] - [3. 1.]  ...................  output (weighted):  [1.1300863 1.4628074] [2. 3.]    original:  [1.1300863  1.46280742] [2. 3.]\n",
      "Greece  x  South Korea :  [0.83575606 0.3108111 ] - [1. 1.]  ...................  output (weighted):  [0.52494496 0.83575606] [0. 1.]    original:  [0.52494496 0.83575606] [0. 1.]\n",
      "Morocco  x  Ivory Coast :  [ 1.28814101 -0.14470053] - [1. 2.]  ...................  output (weighted):  [1.4328415 1.288141 ] [-1.  1.]    original:  [1.43284154 1.28814101] [-1.  1.]\n",
      "Saudi Arabia  x  Finland :  [1.41243052 0.59414059] - [1. 1.]  ...................  output (weighted):  [0.81828994 1.4124305 ] [0. 1.]    original:  [0.81828994 1.41243052] [0. 1.]\n",
      "Test:\n",
      "Qatar  x  Ecuador :  [ 1.39673352 -0.10165739] - [0. 0.]  ...................  output (weighted):  [1.4983909 1.3967335] [0. 0.]    original:  [1.49839091 1.39673352] [0. 0.]\n",
      "England  x  Iran :  [1.43709326 0.50628781] - [0. 0.]  ...................  output (weighted):  [0.93080544 1.4370933 ] [0. 0.]    original:  [0.93080544 1.43709326] [0. 0.]\n",
      "Senegal  x  Netherlands :  [0.51986897 0.1618433 ] - [0. 0.]  ...................  output (weighted):  [0.35802567 0.51986897] [0. 0.]    original:  [0.35802567 0.51986897] [0. 0.]\n",
      "United States  x  Wales :  [0.98317933 0.62167275] - [0. 0.]  ...................  output (weighted):  [0.36150658 0.98317933] [0. 0.]    original:  [0.36150658 0.98317933] [0. 0.]\n",
      "Argentina  x  Saudi Arabia :  [ 1.69638014 -1.19936895] - [0. 0.]  ...................  output (weighted):  [2.895749  1.6963801] [0. 0.]    original:  [2.89574909 1.69638014] [0. 0.]\n",
      "Denmark  x  Tunisia :  [ 1.32700634 -0.29165912] - [0. 0.]  ...................  output (weighted):  [1.6186655 1.3270063] [0. 0.]    original:  [1.61866546 1.32700634] [0. 0.]\n",
      "Mexico  x  Poland :  [1.25122333 0.95395374] - [0. 0.]  ...................  output (weighted):  [0.29726958 1.2512233 ] [0. 0.]    original:  [0.29726958 1.25122333] [0. 0.]\n",
      "France  x  Australia :  [ 1.59810174 -2.19226444] - [0. 0.]  ...................  output (weighted):  [3.7903662 1.5981017] [0. 0.]    original:  [3.79036617 1.59810174] [0. 0.]\n",
      "Morocco  x  Croatia :  [0.66607761 0.70347989] - [0. 0.]  ...................  output (weighted):  [-0.03740227  0.6660776 ] [0. 0.]    original:  [-0.03740227  0.66607761] [0. 0.]\n",
      "Germany  x  Japan :  [ 1.59380603 -0.16250062] - [0. 0.]  ...................  output (weighted):  [1.7563066 1.593806 ] [0. 0.]    original:  [1.75630665 1.59380603] [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "show_predicted_indexes = [i for i in range(0, 10)]\n",
    "\n",
    "print(\"Val:\")\n",
    "show_predictions(dataset, X_val, Y_val, Y_val_pred, show_predicted_indexes, dataset.label_weights)\n",
    "print(\"Test:\")\n",
    "show_predictions(dataset, X_test, np.zeros(Y_test_pred.shape), Y_test_pred, show_predicted_indexes, dataset.label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = tf_models\\3\n",
      "\n",
      "INFO:tensorflow:Assets written to: tf_models\\3\\assets\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "MODEL_DIR = tempfile.gettempdir()\n",
    "version = 3\n",
    "export_path = os.path.join(\"tf_models\", str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "\n",
    "save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'goal_diff': [1.05069733], 'winner_goals': [0.992996514]}, {'goal_diff': [0.487721443], 'winner_goals': [1.76281738]}, {'goal_diff': [-0.405676842], 'winner_goals': [0.963412285]}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": X_test[0:3].tolist()})\n",
    "json_response = requests.post('http://localhost:8501/v1/models/aimatch/versions/1:predict', data=data, headers=headers)\n",
    "predictions_resp = json.loads(json_response.text)['predictions']\n",
    "print(predictions_resp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('aimatch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a3365a4b8fa4d6ece79b74aaf4d470e19d76ad19faef395b86ac40fc70274d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
